{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Minjk121/Minjk121/blob/main/mjk_pipline_iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSkX2TiLzmoy"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%%bash\n",
        "pip install imbalanced-learn\n",
        "pip install pennylane\n",
        "pip install pennylane_cirq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSbEFVqgzpfb"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "import torch\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import torch.nn\n",
        "import matplotlib.pyplot as plt\n",
        "from pennylane.templates import AmplitudeEmbedding\n",
        "import random\n",
        "import os\n",
        "import copy\n",
        "from pennylane_cirq import ops as cirq_ops\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import preprocessing\n",
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uX7j4qBG0En5"
      },
      "outputs": [],
      "source": [
        "dev = qml.device(\"cirq.mixedsimulator\", wires = 2)\n",
        "projector = torch.zeros((2,2))\n",
        "projector[0,0] = 1\n",
        "\n",
        "encoding = 'DenseAngle'\n",
        "channel = 'amplitude damp'\n",
        "p = 0.3\n",
        "split_proportion = 0.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sxJY3gofB_d",
        "outputId": "548c54c2-c465-49e3-88e6-03b23258e0c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[7.2000, 3.2000, 6.0000, 1.8000],\n",
              "         [5.1000, 3.5000, 1.4000, 0.2000],\n",
              "         [7.9000, 3.8000, 6.4000, 2.0000],\n",
              "         [6.4000, 2.8000, 5.6000, 2.1000],\n",
              "         [5.0000, 3.4000, 1.6000, 0.4000],\n",
              "         [4.6000, 3.6000, 1.0000, 0.2000],\n",
              "         [4.4000, 2.9000, 1.4000, 0.2000],\n",
              "         [5.1000, 3.8000, 1.6000, 0.2000],\n",
              "         [5.5000, 3.5000, 1.3000, 0.2000],\n",
              "         [6.1000, 2.6000, 5.6000, 1.4000],\n",
              "         [6.4000, 2.7000, 5.3000, 1.9000],\n",
              "         [5.0000, 3.5000, 1.3000, 0.3000],\n",
              "         [5.8000, 2.7000, 5.1000, 1.9000],\n",
              "         [6.0000, 2.2000, 5.0000, 1.5000],\n",
              "         [5.1000, 3.5000, 1.4000, 0.3000],\n",
              "         [7.7000, 2.6000, 6.9000, 2.3000],\n",
              "         [4.3000, 3.0000, 1.1000, 0.1000],\n",
              "         [6.3000, 2.9000, 5.6000, 1.8000],\n",
              "         [4.6000, 3.2000, 1.4000, 0.2000],\n",
              "         [4.8000, 3.4000, 1.6000, 0.2000],\n",
              "         [6.1000, 3.0000, 4.9000, 1.8000],\n",
              "         [5.9000, 3.0000, 5.1000, 1.8000],\n",
              "         [5.4000, 3.9000, 1.3000, 0.4000],\n",
              "         [5.4000, 3.4000, 1.7000, 0.2000],\n",
              "         [5.0000, 3.6000, 1.4000, 0.2000],\n",
              "         [6.5000, 3.0000, 5.5000, 1.8000],\n",
              "         [6.5000, 3.0000, 5.8000, 2.2000],\n",
              "         [6.2000, 2.8000, 4.8000, 1.8000],\n",
              "         [6.3000, 3.4000, 5.6000, 2.4000],\n",
              "         [6.5000, 3.2000, 5.1000, 2.0000],\n",
              "         [5.8000, 2.7000, 5.1000, 1.9000],\n",
              "         [4.9000, 3.0000, 1.4000, 0.2000],\n",
              "         [6.7000, 3.3000, 5.7000, 2.5000],\n",
              "         [5.5000, 4.2000, 1.4000, 0.2000],\n",
              "         [4.8000, 3.1000, 1.6000, 0.2000],\n",
              "         [5.1000, 3.8000, 1.5000, 0.3000],\n",
              "         [5.0000, 3.3000, 1.4000, 0.2000],\n",
              "         [5.2000, 4.1000, 1.5000, 0.1000],\n",
              "         [5.4000, 3.7000, 1.5000, 0.2000],\n",
              "         [7.7000, 3.0000, 6.1000, 2.3000],\n",
              "         [5.1000, 3.3000, 1.7000, 0.5000],\n",
              "         [4.8000, 3.0000, 1.4000, 0.3000],\n",
              "         [7.2000, 3.0000, 5.8000, 1.6000],\n",
              "         [5.6000, 2.8000, 4.9000, 2.0000],\n",
              "         [5.1000, 3.7000, 1.5000, 0.4000],\n",
              "         [6.9000, 3.1000, 5.4000, 2.1000],\n",
              "         [7.1000, 3.0000, 5.9000, 2.1000],\n",
              "         [6.7000, 3.3000, 5.7000, 2.1000],\n",
              "         [6.4000, 3.2000, 5.3000, 2.3000],\n",
              "         [7.3000, 2.9000, 6.3000, 1.8000],\n",
              "         [5.7000, 2.5000, 5.0000, 2.0000],\n",
              "         [6.7000, 2.5000, 5.8000, 1.8000],\n",
              "         [4.9000, 3.1000, 1.5000, 0.1000],\n",
              "         [6.5000, 3.0000, 5.2000, 2.0000],\n",
              "         [5.4000, 3.9000, 1.7000, 0.4000],\n",
              "         [7.4000, 2.8000, 6.1000, 1.9000],\n",
              "         [6.7000, 3.1000, 5.6000, 2.4000],\n",
              "         [6.9000, 3.2000, 5.7000, 2.3000],\n",
              "         [4.6000, 3.1000, 1.5000, 0.2000],\n",
              "         [6.4000, 3.1000, 5.5000, 1.8000],\n",
              "         [6.8000, 3.2000, 5.9000, 2.3000],\n",
              "         [6.2000, 3.4000, 5.4000, 2.3000],\n",
              "         [5.3000, 3.7000, 1.5000, 0.2000],\n",
              "         [5.8000, 2.8000, 5.1000, 2.4000],\n",
              "         [4.7000, 3.2000, 1.3000, 0.2000],\n",
              "         [6.3000, 2.5000, 5.0000, 1.9000],\n",
              "         [5.0000, 3.2000, 1.2000, 0.2000],\n",
              "         [5.8000, 4.0000, 1.2000, 0.2000],\n",
              "         [7.7000, 2.8000, 6.7000, 2.0000],\n",
              "         [5.7000, 4.4000, 1.5000, 0.4000],\n",
              "         [5.2000, 3.5000, 1.5000, 0.2000],\n",
              "         [4.6000, 3.4000, 1.4000, 0.3000],\n",
              "         [4.8000, 3.0000, 1.4000, 0.1000],\n",
              "         [7.2000, 3.6000, 6.1000, 2.5000],\n",
              "         [6.0000, 3.0000, 4.8000, 1.8000],\n",
              "         [6.8000, 3.0000, 5.5000, 2.1000],\n",
              "         [6.3000, 2.8000, 5.1000, 1.5000],\n",
              "         [7.6000, 3.0000, 6.6000, 2.1000],\n",
              "         [4.9000, 3.1000, 1.5000, 0.1000],\n",
              "         [5.0000, 3.5000, 1.6000, 0.6000]], dtype=torch.float64),\n",
              " tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
              "         0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
              "         0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
              "         0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
              "         0., 1., 1., 1., 1., 1., 0., 0.], dtype=torch.float64),\n",
              " tensor([[4.9000, 3.1000, 1.5000, 0.1000],\n",
              "         [5.1000, 3.4000, 1.5000, 0.2000],\n",
              "         [6.3000, 3.3000, 6.0000, 2.5000],\n",
              "         [5.0000, 3.0000, 1.6000, 0.2000],\n",
              "         [4.9000, 2.5000, 4.5000, 1.7000],\n",
              "         [5.7000, 3.8000, 1.7000, 0.3000],\n",
              "         [5.1000, 3.8000, 1.9000, 0.4000],\n",
              "         [4.8000, 3.4000, 1.9000, 0.2000],\n",
              "         [6.9000, 3.1000, 5.1000, 2.3000],\n",
              "         [4.5000, 2.3000, 1.3000, 0.3000],\n",
              "         [5.2000, 3.4000, 1.4000, 0.2000],\n",
              "         [7.7000, 3.8000, 6.7000, 2.2000],\n",
              "         [4.4000, 3.0000, 1.3000, 0.2000],\n",
              "         [6.3000, 2.7000, 4.9000, 1.8000],\n",
              "         [4.4000, 3.2000, 1.3000, 0.2000],\n",
              "         [5.0000, 3.4000, 1.5000, 0.2000],\n",
              "         [6.7000, 3.0000, 5.2000, 2.3000],\n",
              "         [6.4000, 2.8000, 5.6000, 2.2000],\n",
              "         [4.7000, 3.2000, 1.6000, 0.2000],\n",
              "         [5.4000, 3.4000, 1.5000, 0.4000]], dtype=torch.float64),\n",
              " tensor([0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1.,\n",
              "         0., 0.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "def load_data(split_proportion=0.8):\n",
        "  df = pandas.read_csv('https://raw.githubusercontent.com/mcmahon-lab/qml/main/Robust/FIG_10/IRIS.csv?token=AJGBMBPCPB7OZIXRDIQ7OR3BX6QBI')\n",
        "  # use 2 target values\n",
        "  df = df.loc[df[\"species\"] != \"Iris-versicolor\"]\n",
        "  df.species[df.species == \"Iris-setosa\"] = 0\n",
        "  df.species[df.species == \"Iris-virginica\"] = 1\n",
        "  data = df.filter(items=['sepal_length', 'sepal_width','petal_length','petal_width'])\n",
        "  labels = df.filter(items=['species'])\n",
        "  length = len(df)\n",
        "  df = df.sample(frac = 1).astype(float)\n",
        "  cut_off = (int)(length*split_proportion)\n",
        "  train = torch.tensor(df[:cut_off].drop(columns=[\"species\"]).values, dtype=torch.float64)\n",
        "  val = torch.tensor(df[cut_off:].drop(columns=[\"species\"]).values, dtype=torch.float64)\n",
        "  train_target = torch.tensor(df.species[:cut_off].values, dtype=torch.float64)\n",
        "  val_target = torch.tensor(df.species[cut_off:].values, dtype=torch.float64)\n",
        "  # train_data = torch.tensor(train_data.values, dtype=torch.float64)\n",
        "  # test_data = torch.tensor(test_data.values, dtype=torch.float64)\n",
        "  # train_labels = torch.tensor(train_labels.values, dtype=torch.float64)\n",
        "  # test_labels = torch.tensor(train_labels.values, dtype=torch.float64)\n",
        "  # return train_data, test_data, train_labels, test_labels\n",
        "  return torch.tensor(train), torch.tensor(train_target), val, val_target\n",
        "load_data(0.8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhEBUql80Mdd"
      },
      "outputs": [],
      "source": [
        "dev = qml.device('cirq.mixedsimulator', wires=2)\n",
        "@qml.qnode(dev, interface = \"torch\")\n",
        "def circuit(inputs, params_circ, params_emb):\n",
        "  global encoding, channel, noise, p\n",
        "  if encoding == 'amplitude':\n",
        "      AmplitudeEmbedding(features = inputs, wires = range(2), normalize = True)\n",
        "  elif encoding == 'DenseAngle':\n",
        "      qml.RY(2*params_emb[0]*inputs[0], wires= 0)\n",
        "      qml.PhaseShift(2*params_emb[1]*inputs[1], wires = 0)\n",
        "      qml.RY(2*params_emb[2]*inputs[2], wires= 1)\n",
        "      qml.PhaseShift(2*params_emb[3]*inputs[3], wires = 1)\n",
        "  elif encoding == 'SuperDenseAngle':\n",
        "      qml.RY(2*params_emb[0]*inputs[0] + 2*params_emb[1]*inputs[1], wires = 0)\n",
        "      qml.RY(2*params_emb[2]*inputs[2] + 2*params_emb[3]*inputs[3], wires = 1)\n",
        "  ansatz(params_circ)\n",
        "  if noise:\n",
        "    if channel == 'pauli':\n",
        "      #TODO\n",
        "      pass\n",
        "    elif channel == 'depolarizing':\n",
        "      cirq_ops.Depolarize(p, wires = 0)\n",
        "      cirq_ops.Depolarize(p, wires = 1)\n",
        "    elif channel == 'amplitude damp':\n",
        "      cirq_ops.AmplitudeDamp(p, wires = 0)\n",
        "      cirq_ops.AmplitudeDamp(p, wires = 1)\n",
        "  return qml.expval(qml.Hermitian(projector, wires = 0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kImBB1vy0OPx"
      },
      "outputs": [],
      "source": [
        "def ansatz(params_circ):\n",
        "  qml.Rot(2*params_circ[0], 2*params_circ[1], 2*params_circ[2], wires = 0)\n",
        "  qml.Rot(2*params_circ[3], 2*params_circ[4], 2*params_circ[5], wires = 1)\n",
        "  qml.CNOT(wires=[0, 1])\n",
        "  qml.Rot(2*params_circ[6], 2*params_circ[7], 2*params_circ[8], wires = 0)\n",
        "  qml.Rot(2*params_circ[9], 2*params_circ[10], 2*params_circ[11], wires = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4d0WnO20Pz_"
      },
      "outputs": [],
      "source": [
        "def freeze_layer(QNN, n):\n",
        "    \"\"\"\n",
        "    Freeze the nth layer of QNN.\n",
        "    n = 1: frozen layer is the unitary layer.\n",
        "    n = 0: frozen layer is the embedding layer.\n",
        "    \"\"\"\n",
        "    for idx, param in enumerate(QNN.parameters()):\n",
        "        if idx == n:\n",
        "            param.requires_grad = False\n",
        "        else:\n",
        "            param.requires_grad = True\n",
        "    return QNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC57xPyK0SAh",
        "outputId": "891001df-0b3f-4a83-f3f5-1ab7dfb4b19c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        }
      ],
      "source": [
        "global noise, encoding, channel, batch_size, num_of_runs\n",
        "params_shapes = {\"params_circ\": 12, \"params_emb\": 4}\n",
        "cost_funcs = [torch.nn.BCELoss(),torch.nn.MSELoss()]\n",
        "num_folds = [4, 8, 12]\n",
        "best_param = None\n",
        "best_score = 0\n",
        "best_model = None\n",
        "lrs = [1, 0.1, 0.01, 0.001]\n",
        "encode_lrs = [1, 0.1, 0.01, 0.001]\n",
        "itr = 1\n",
        "encode_itrs = 1\n",
        "batch_sizes = [10, 12, 14]\n",
        "num_of_runs = 1\n",
        "train, train_target, val, val_target  = load_data(0.8)\n",
        "shuffler = torch.randperm(len(train))\n",
        "train = train[shuffler]\n",
        "train_target = train_target[shuffler]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdgOzjAS0Tn3"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, label):\n",
        "  accum = 0\n",
        "  length = len(output)\n",
        "  for i in range(length):\n",
        "    if label[i] - output[i] >= -0.5 and label[i] - output[i] <= 0.5:\n",
        "      accum += 1\n",
        "  return accum/length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57CjIfdV1BHE"
      },
      "outputs": [],
      "source": [
        "for batch_size in batch_sizes:\n",
        "  for cost in cost_funcs:\n",
        "    for lr in lrs:\n",
        "        for encode_lr in encode_lrs:\n",
        "            for num_fold in num_folds:\n",
        "                kf = KFold(n_splits=num_fold)\n",
        "                score = 0\n",
        "                for train_index, test_index in kf.split(train):\n",
        "                  train_data, test_data = train[train_index], train[test_index]\n",
        "                  train_label, test_label = train_target[train_index], train_target[test_index]\n",
        "                  #train circuit parameters\n",
        "                  noise = False\n",
        "                  QNN = qml.qnn.TorchLayer(circuit, params_shapes)\n",
        "                  QNN = freeze_layer(QNN, 1)\n",
        "                  opt_circuit = torch.optim.Adam(QNN.parameters(), lr = lr)\n",
        "                  lowest_cost_noise = 1e10\n",
        "                  lowest_QNN_state_noise = None\n",
        "                  QNN_state = {\"params_circ\": torch.FloatTensor(np.random.uniform(0,2*np.pi,12)), \"params_emb\": torch.FloatTensor(np.random.uniform(0,2*np.pi,4))}\n",
        "                  QNN.load_state_dict(QNN_state)\n",
        "                  lowest_cost = 1e10\n",
        "                  lowest_QNN_state = None\n",
        "                  for iter in range(itr):\n",
        "                    total_tr_cost = 0\n",
        "                    #stochastic gradient decent\n",
        "                    for i in range(0, len(train_data), batch_size):\n",
        "                        opt_circuit.zero_grad()\n",
        "                        end_index = i+batch_size\n",
        "                        train_pts = train_data[i:end_index]\n",
        "                        output = QNN(train_pts)\n",
        "                        train_cost = cost(output,train_label[i:end_index])\n",
        "                        total_tr_cost += train_cost.data.numpy()\n",
        "                        train_cost.backward()\n",
        "                        opt_circuit.step()\n",
        "                    if lowest_cost > total_tr_cost:\n",
        "                      lowest_cost = total_tr_cost\n",
        "                      lowest_QNN_state = copy.deepcopy(QNN.state_dict())\n",
        "                    print((str)(run)+\" runs, \"+(str)(iter)+\" iterations, cost is \"+(str)(total_tr_cost)+\"，QNN state: \"+(str)(QNN.state_dict()))\n",
        "                  print(\"lowest cost: \"+(str)(lowest_cost)+\", lowest_QNN_state: \"+(str)(lowest_QNN_state ))\n",
        "                  noise = True\n",
        "                  QNN_noise = qml.qnn.TorchLayer(circuit, params_shapes)\n",
        "                  QNN_noise.load_state_dict(lowest_QNN_state)\n",
        "                  QNN_noise = freeze_layer(QNN_noise, 0)\n",
        "                  opt_embeddings = torch.optim.Adam(QNN_noise.parameters(), lr = encode_lr)\n",
        "                  for iter in range(encode_itrs):\n",
        "                    total_tr_cost_noise = 0\n",
        "                    #stochastic gradient decent\n",
        "                    for i in range(0, len(train_data), batch_size):\n",
        "                      # print(QNN_noise.state_dict())\n",
        "                      opt_embeddings.zero_grad()\n",
        "                      end_index = i+batch_size\n",
        "                      train_pts = train_data[i:end_index]\n",
        "                      output_noise = QNN_noise(train_pts)\n",
        "                      train_cost_noise = cost(output_noise,train_label[i:end_index])\n",
        "                      total_tr_cost_noise += train_cost_noise.data.numpy()\n",
        "                      train_cost_noise.backward()\n",
        "                      opt_embeddings.step()\n",
        "                    if lowest_cost_noise > total_tr_cost_noise:\n",
        "                      lowest_cost_noise = total_tr_cost_noise\n",
        "                      lowest_QNN_state_noise= copy.deepcopy(QNN_noise.state_dict())\n",
        "                  #   print((str)(run)+\" runs, \"+(str)(iter)+\" iterations, cost noise is \"+(str)(total_tr_cost_noise)+\"，QNN state noise: \"+(str)(QNN_noise.state_dict()))\n",
        "                  # print(\"so far lowest cost is \"+(str)(lowest_cost_noise))\n",
        "                  noise = True\n",
        "                  QNN_test = qml.qnn.TorchLayer(circuit, params_shapes)\n",
        "                  QNN_test.load_state_dict(lowest_QNN_state_noise)\n",
        "                  QNN_test.state_dict().requires_grad = False\n",
        "                  output_test = QNN_test(test_data)\n",
        "                  accur = accuracy(output_test, test_label)\n",
        "                  score += accur\n",
        "                score = score/num_fold\n",
        "                if score > best_score:\n",
        "                  best_param, best_score, best_model = (batch_size, cost, lr, encode_lr, num_fold), score, lowest_QNN_state_noise\n",
        "print(\"best param: \"+(str)(best_param))\n",
        "print(\"best score: \"+(str)(best_score))\n",
        "print(\"best qnn: \"+(str)(best_model))\n",
        "file = open('results1.txt','w')\n",
        "file.write(\"best param: \"+(str)(best_param)+'\\n')\n",
        "file.write(\"best score: \"+(str)(best_score)+'\\n')\n",
        "file.write(\"best qnn: \"+(str)(best_model)+'\\n')\n",
        "file.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGjGId1Sr2PL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mjk-pipline-iris",
      "provenance": [],
      "authorship_tag": "ABX9TyMEqa3AOALgw6RF3UCLr9DB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}